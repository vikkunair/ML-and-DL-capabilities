{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT_Token_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7DMnIu_FPhz"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcPFVhyktZRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131de2b0-8cae-4da0-f93c-889bf856230b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9V4U12asGoM"
      },
      "source": [
        "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
        "    \"\"\"\n",
        "    Mask the upper half of the dot product matrix in self attention.\n",
        "    This prevents flow of information from future tokens to current token.\n",
        "    1's in the lower triangle, counting from the lower right corner.\n",
        "    \"\"\"\n",
        "    i = tf.range(n_dest)[:, None]\n",
        "    j = tf.range(n_src)\n",
        "    m = i >= j - n_src + n_dest\n",
        "    mask = tf.cast(m, dtype)\n",
        "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "    mult = tf.concat(\n",
        "        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "    )\n",
        "    return tf.tile(mask, mult)\n",
        "\n",
        "\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads, embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        attention_output = self.att(inputs, inputs, attention_mask=causal_mask)\n",
        "        attention_output = self.dropout1(attention_output)\n",
        "        out1 = self.layernorm1(inputs + attention_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDf8hgegsKiF"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWLHC70QtC5F"
      },
      "source": [
        "vocab_size = 20000  # Only consider the top 20k words\n",
        "maxlen = 80  # Max sequence size\n",
        "embed_dim = 256  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "feed_forward_dim = 256  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "\n",
        "def create_model():\n",
        "    inputs = layers.Input(shape=(maxlen,), dtype=tf.int32)\n",
        "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "    x = embedding_layer(inputs)\n",
        "    transformer_block = TransformerBlock(embed_dim, num_heads, feed_forward_dim)\n",
        "    x = transformer_block(x)\n",
        "    outputs = layers.Dense(vocab_size)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=[outputs, x])\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    model.compile(\n",
        "        \"adam\", loss=[loss_fn, None],\n",
        "    )  # No loss and optimization based on word embeddings from transformer block\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSfZjZ8ZtJ9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d6c3e09-cb28-4fd6-c8b1-13b149486ca5"
      },
      "source": [
        "batch_size = 30\n",
        "\n",
        "# The dataset contains each review in a separate text file\n",
        "# The text files are present in four different folders\n",
        "# Create a list all files\n",
        "filenames = []\n",
        "directories = [\n",
        "    \"/content/gdrive/MyDrive/dissertation_word_dataset\",\n",
        "]\n",
        "for dir in directories:\n",
        "    for f in os.listdir(dir):\n",
        "        filenames.append(os.path.join(dir, f))\n",
        "\n",
        "print(f\"{len(filenames)} files\")\n",
        "\n",
        "# Create a dataset from text files\n",
        "random.shuffle(filenames)\n",
        "text_ds = tf.data.TextLineDataset(filenames)\n",
        "text_ds = text_ds.shuffle(buffer_size=256)\n",
        "text_ds = text_ds.batch(batch_size)\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    \"\"\" Remove html line-break tags and handle punctuation \"\"\"\n",
        "    lowercased = tf.strings.lower(input_string)\n",
        "    stripped_html = tf.strings.regex_replace(lowercased, \"<br />\", \" \")\n",
        "    return tf.strings.regex_replace(stripped_html, f\"([{string.punctuation}])\", r\" \\1\")\n",
        "\n",
        "\n",
        "# Create a vectorization layer and adapt it to the text\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size - 1,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=maxlen + 1,\n",
        ")\n",
        "vectorize_layer.adapt(text_ds)\n",
        "vocab = vectorize_layer.get_vocabulary()  # To get words back from token indices\n",
        "\n",
        "\n",
        "def prepare_lm_inputs_labels(text):\n",
        "    \"\"\"\n",
        "    Shift word sequences by 1 position so that the target for position (i) is\n",
        "    word at position (i+1). The model will use all words up till position (i)\n",
        "    to predict the next word.\n",
        "    \"\"\"\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer(text)\n",
        "    x = tokenized_sentences[:, :-1]\n",
        "    y = tokenized_sentences[:, 1:]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "text_ds = text_ds.map(prepare_lm_inputs_labels)\n",
        "text_ds = text_ds.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0GlnRJRIfmz",
        "outputId": "d50be128-a93a-4b65-d753-6715d8672acb"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " ',',\n",
              " ')',\n",
              " ':',\n",
              " \"'\",\n",
              " '=',\n",
              " '\"',\n",
              " '(',\n",
              " 'self',\n",
              " ']',\n",
              " '.',\n",
              " ',0',\n",
              " '_',\n",
              " 'if',\n",
              " 'def',\n",
              " '(self',\n",
              " 'return',\n",
              " '[',\n",
              " '0',\n",
              " '-',\n",
              " 'in',\n",
              " 'u',\n",
              " 'the',\n",
              " \"'m\",\n",
              " ',1',\n",
              " 'is',\n",
              " 'for',\n",
              " '1',\n",
              " 'import',\n",
              " '+',\n",
              " 'not',\n",
              " ',3',\n",
              " '`',\n",
              " 'none',\n",
              " ',2',\n",
              " '}',\n",
              " 'a',\n",
              " 'from',\n",
              " '>',\n",
              " '*',\n",
              " 'and',\n",
              " 'else',\n",
              " '2',\n",
              " 'to',\n",
              " 'assert',\n",
              " '%s',\n",
              " 'of',\n",
              " ';',\n",
              " '{',\n",
              " '3',\n",
              " '_name',\n",
              " 'np',\n",
              " '[0',\n",
              " 'or',\n",
              " 'os',\n",
              " 'raise',\n",
              " '%',\n",
              " 'name',\n",
              " '.get',\n",
              " 'class',\n",
              " '=none',\n",
              " '.path',\n",
              " '_equal',\n",
              " 'as',\n",
              " 'result',\n",
              " '[1',\n",
              " 'try',\n",
              " 'true',\n",
              " 'with',\n",
              " 'value',\n",
              " '.append',\n",
              " '/',\n",
              " 'false',\n",
              " 'except',\n",
              " '_dir',\n",
              " 'elif',\n",
              " 'data',\n",
              " '<',\n",
              " \"'v\",\n",
              " '_version',\n",
              " 'test',\n",
              " '_path',\n",
              " 'path',\n",
              " ',4',\n",
              " 'be',\n",
              " '-1',\n",
              " 'isinstance',\n",
              " '_init',\n",
              " '.join',\n",
              " 'c',\n",
              " 'print',\n",
              " 'x',\n",
              " 'get',\n",
              " '.0',\n",
              " 'list',\n",
              " 'other',\n",
              " 'len',\n",
              " 'version',\n",
              " 'this',\n",
              " 'b',\n",
              " '=true',\n",
              " '!',\n",
              " 'expected',\n",
              " 'sys',\n",
              " '4',\n",
              " 'pip',\n",
              " \"'x\",\n",
              " 's',\n",
              " '_info',\n",
              " '.name',\n",
              " '_type',\n",
              " 'file',\n",
              " '=false',\n",
              " 'an',\n",
              " 'key',\n",
              " '|',\n",
              " 'dtype',\n",
              " 'pass',\n",
              " 'i',\n",
              " '(x',\n",
              " 'that',\n",
              " 'string',\n",
              " 'f',\n",
              " '_file',\n",
              " 'token',\n",
              " '(0',\n",
              " 'type',\n",
              " 'url',\n",
              " '(a',\n",
              " 'str',\n",
              " '?',\n",
              " '5',\n",
              " 'set',\n",
              " '*kwargs',\n",
              " '_str',\n",
              " '_to',\n",
              " 'default',\n",
              " '.array',\n",
              " 'r',\n",
              " 'loc',\n",
              " '(np',\n",
              " '(1',\n",
              " '(path',\n",
              " 'dist',\n",
              " '_options',\n",
              " '.format',\n",
              " '(name',\n",
              " 'index',\n",
              " 'e',\n",
              " '68',\n",
              " 'are',\n",
              " '_array',\n",
              " ',machinestate',\n",
              " '_internal',\n",
              " '.error',\n",
              " '_get',\n",
              " 'line',\n",
              " 're',\n",
              " 'v',\n",
              " '_url',\n",
              " 'match',\n",
              " '(r',\n",
              " '_data',\n",
              " 'int',\n",
              " '*args',\n",
              " 'valueerror',\n",
              " '6',\n",
              " '_value',\n",
              " 'new',\n",
              " 'n',\n",
              " 'y',\n",
              " '(none',\n",
              " 'array',\n",
              " 'will',\n",
              " 'it',\n",
              " 'tm',\n",
              " 'logger',\n",
              " '(s',\n",
              " '\"a',\n",
              " '_from',\n",
              " '.assert',\n",
              " ',5',\n",
              " 'df',\n",
              " '.split',\n",
              " 'by',\n",
              " 'yield',\n",
              " 'object',\n",
              " '(result',\n",
              " 'parse',\n",
              " '_index',\n",
              " '.add',\n",
              " 'req',\n",
              " 'on',\n",
              " '=self',\n",
              " '@property',\n",
              " 'use',\n",
              " '10',\n",
              " 'super',\n",
              " '_class',\n",
              " 'all',\n",
              " 'msg',\n",
              " 'tuple',\n",
              " '(data',\n",
              " 'optional',\n",
              " 'd',\n",
              " 'values',\n",
              " '(u',\n",
              " 'p',\n",
              " '.version',\n",
              " 'args',\n",
              " '=0',\n",
              " \"'3\",\n",
              " ',255',\n",
              " '_check',\n",
              " '7',\n",
              " 'node',\n",
              " '_string',\n",
              " 'm',\n",
              " 'options',\n",
              " '.parser',\n",
              " 'returns',\n",
              " '.dtype',\n",
              " 'output',\n",
              " '_cache',\n",
              " 't',\n",
              " 'while',\n",
              " 'text',\n",
              " '_list',\n",
              " 'axis',\n",
              " 'filename',\n",
              " 'l',\n",
              " 'method',\n",
              " '(os',\n",
              " '\"name',\n",
              " '(2',\n",
              " '8',\n",
              " 'out',\n",
              " '_args',\n",
              " ',253',\n",
              " 'must',\n",
              " 'range',\n",
              " 'obj',\n",
              " 'getattr',\n",
              " '(other',\n",
              " 'check',\n",
              " '.utils',\n",
              " 'base',\n",
              " 'build',\n",
              " 'var',\n",
              " 'dict',\n",
              " 'has',\n",
              " 'item',\n",
              " '\"data',\n",
              " '.write',\n",
              " '[2',\n",
              " '=1',\n",
              " 'pd',\n",
              " 'k',\n",
              " 'log',\n",
              " '(value',\n",
              " '.tree',\n",
              " '_dict',\n",
              " '[i',\n",
              " 'command',\n",
              " '(object',\n",
              " '\"b',\n",
              " 'any',\n",
              " 'break',\n",
              " '_dirs',\n",
              " 'cls',\n",
              " '.startswith',\n",
              " '.debug',\n",
              " 'prefix',\n",
              " 'link',\n",
              " '^',\n",
              " 'end',\n",
              " 'can',\n",
              " 'continue',\n",
              " 'error',\n",
              " 'module',\n",
              " '_set',\n",
              " '%r',\n",
              " '_size',\n",
              " ':param',\n",
              " '(3',\n",
              " 'element',\n",
              " '(b',\n",
              " 'distribution',\n",
              " '.set',\n",
              " 'files',\n",
              " '_filename',\n",
              " '-01',\n",
              " 'input',\n",
              " 'number',\n",
              " \"'s\",\n",
              " '(namespaces',\n",
              " '(f',\n",
              " 'datetime',\n",
              " 'response',\n",
              " 'integer',\n",
              " 'instring',\n",
              " '9',\n",
              " 'used',\n",
              " '12',\n",
              " '.items',\n",
              " '_len',\n",
              " 'encoding',\n",
              " 'format',\n",
              " 'distutils',\n",
              " ':class',\n",
              " '.lower',\n",
              " 'request',\n",
              " 'example',\n",
              " 'warnings',\n",
              " 'attr',\n",
              " '.compile',\n",
              " 'at',\n",
              " '.copy',\n",
              " '.5',\n",
              " 'size',\n",
              " 'given',\n",
              " '.state',\n",
              " '_parse',\n",
              " 'hasattr',\n",
              " 'max',\n",
              " \"'t\",\n",
              " '_frame',\n",
              " 'when',\n",
              " 'series',\n",
              " 'no',\n",
              " 'metadata',\n",
              " 'ret',\n",
              " 'word',\n",
              " '_raises',\n",
              " '_char',\n",
              " 'user',\n",
              " 'cache',\n",
              " 'headers',\n",
              " 'found',\n",
              " '_config',\n",
              " '.is',\n",
              " '_for',\n",
              " '.info',\n",
              " '_key',\n",
              " '_all',\n",
              " '.nan',\n",
              " 'option',\n",
              " 'mode',\n",
              " 'res',\n",
              " 'open',\n",
              " 'only',\n",
              " '.pop',\n",
              " 'python',\n",
              " 'extra',\n",
              " '_vendor',\n",
              " '_command',\n",
              " '_option',\n",
              " '.read',\n",
              " '\"type',\n",
              " '_header',\n",
              " 'exception',\n",
              " 'directory',\n",
              " '.index',\n",
              " '(url',\n",
              " 'package',\n",
              " '-8',\n",
              " 'function',\n",
              " '_re',\n",
              " '.warn',\n",
              " 'target',\n",
              " 'expression',\n",
              " 'parser',\n",
              " '(instring',\n",
              " '\"urllib',\n",
              " '255',\n",
              " '20',\n",
              " '_build',\n",
              " '(cls',\n",
              " '(valueerror',\n",
              " 'info',\n",
              " 'names',\n",
              " 'val',\n",
              " '_is',\n",
              " 'install',\n",
              " '.shape',\n",
              " 'start',\n",
              " 'exc',\n",
              " 'kwargs',\n",
              " 'bool',\n",
              " '.strip',\n",
              " '(key',\n",
              " \"'a\",\n",
              " 'parts',\n",
              " 'wheel',\n",
              " '(dist',\n",
              " 'dataframe',\n",
              " '&',\n",
              " 'current',\n",
              " '(c',\n",
              " '11',\n",
              " 'should',\n",
              " 'source',\n",
              " 'which',\n",
              " '_python',\n",
              " 'one',\n",
              " 'tokens',\n",
              " '_types',\n",
              " 'platform',\n",
              " 'you',\n",
              " '_files',\n",
              " '.replace',\n",
              " 'pytest',\n",
              " 'action',\n",
              " '_opts',\n",
              " 'operator',\n",
              " 'movedattribute',\n",
              " '16',\n",
              " 'float',\n",
              " 'logging',\n",
              " '.match',\n",
              " '_with',\n",
              " '_module',\n",
              " 'numpy',\n",
              " 'first',\n",
              " 'content',\n",
              " 'tag',\n",
              " '\"unexpected',\n",
              " '(e',\n",
              " '_names',\n",
              " '_map',\n",
              " ':00',\n",
              " 'typeerror',\n",
              " '15',\n",
              " '\\\\',\n",
              " 'add',\n",
              " 'func',\n",
              " 'requirement',\n",
              " 'scheme',\n",
              " '_state',\n",
              " 'see',\n",
              " '.egg',\n",
              " 'group',\n",
              " '(n',\n",
              " '_base',\n",
              " '(token',\n",
              " 'del',\n",
              " 'parsed',\n",
              " '_error',\n",
              " '.tokenqueue',\n",
              " '@pytest',\n",
              " 'parameters',\n",
              " '.parse',\n",
              " '_dtype',\n",
              " '(obj',\n",
              " '_series',\n",
              " 'using',\n",
              " 'unicode',\n",
              " 'find',\n",
              " 'ext',\n",
              " '_prefix',\n",
              " '_metadata',\n",
              " '_import',\n",
              " '{0',\n",
              " '.parsestring',\n",
              " '_field',\n",
              " '%d',\n",
              " 'message',\n",
              " '_table',\n",
              " 'tokentypes',\n",
              " 'timeout',\n",
              " 'read',\n",
              " 'lambda',\n",
              " '_context',\n",
              " 'have',\n",
              " 'field',\n",
              " '30',\n",
              " '(i',\n",
              " '(d',\n",
              " '.extend',\n",
              " '[3',\n",
              " '(str',\n",
              " '32',\n",
              " \"'utf\",\n",
              " '.mark',\n",
              " '(v',\n",
              " 'importerror',\n",
              " 'cmd',\n",
              " '50',\n",
              " '_requires',\n",
              " '14',\n",
              " '_install',\n",
              " '.start',\n",
              " ',6',\n",
              " 'config',\n",
              " '31',\n",
              " '.arange',\n",
              " '.stream',\n",
              " '_almost',\n",
              " '.close',\n",
              " 'dest',\n",
              " 'mask',\n",
              " '.group',\n",
              " '_run',\n",
              " '(filename',\n",
              " '_func',\n",
              " 'make',\n",
              " 'copy',\n",
              " 'header',\n",
              " 'expr',\n",
              " 'location',\n",
              " 'order',\n",
              " 'also',\n",
              " 'resource',\n",
              " '.1',\n",
              " '_req',\n",
              " '13',\n",
              " '.request',\n",
              " \"'b\",\n",
              " '\"c',\n",
              " '_running',\n",
              " '253',\n",
              " '.encode',\n",
              " '\"html',\n",
              " 'parserelement',\n",
              " '_max',\n",
              " 'pattern',\n",
              " 'lines',\n",
              " '$',\n",
              " '.build',\n",
              " '_id',\n",
              " '.setparseaction',\n",
              " ')s',\n",
              " 'absolute',\n",
              " '(version',\n",
              " 'date',\n",
              " 'left',\n",
              " 'entry',\n",
              " 'may',\n",
              " '=2',\n",
              " '_values',\n",
              " 'errors',\n",
              " '_repr',\n",
              " 'write',\n",
              " '24',\n",
              " '[key',\n",
              " 'code',\n",
              " '_by',\n",
              " 'next',\n",
              " 'spec',\n",
              " '17',\n",
              " 'marker',\n",
              " '_buffer',\n",
              " '60',\n",
              " 'script',\n",
              " '_int',\n",
              " \"'name\",\n",
              " '(len',\n",
              " '(req',\n",
              " '-9',\n",
              " \"'iso\",\n",
              " '.core',\n",
              " '_headers',\n",
              " 'but',\n",
              " 'results',\n",
              " 'label',\n",
              " 'help',\n",
              " 'stream',\n",
              " '_link',\n",
              " '_resources',\n",
              " \"'\\\\n\",\n",
              " '[name',\n",
              " 'bytes',\n",
              " '[self',\n",
              " 'parent',\n",
              " '_line',\n",
              " '_default',\n",
              " '23',\n",
              " '.endswith',\n",
              " 'root',\n",
              " '_format',\n",
              " '22',\n",
              " 'old',\n",
              " '_expr',\n",
              " '.url',\n",
              " '.openelements',\n",
              " 'zip',\n",
              " '.random',\n",
              " '_read',\n",
              " '_future',\n",
              " '40',\n",
              " '_function',\n",
              " '_in',\n",
              " '.distribution',\n",
              " 'err',\n",
              " 'length',\n",
              " '25',\n",
              " '-2',\n",
              " 'paths',\n",
              " '*kw',\n",
              " '_range',\n",
              " 'shape',\n",
              " '(msg',\n",
              " 'include',\n",
              " '.exists',\n",
              " 'tarinfo',\n",
              " '21',\n",
              " 'mypy',\n",
              " 'host',\n",
              " 'returned',\n",
              " 'pkg',\n",
              " 'address',\n",
              " 'create',\n",
              " 'body',\n",
              " '18',\n",
              " '.py',\n",
              " 'context',\n",
              " '_seg',\n",
              " '.assertequal',\n",
              " 'specified',\n",
              " '.find',\n",
              " 'time',\n",
              " '.raises',\n",
              " '@classmethod',\n",
              " 'pandas',\n",
              " \"'c\",\n",
              " '(10',\n",
              " 'more',\n",
              " '(t',\n",
              " '(lambda',\n",
              " '.install',\n",
              " '_no',\n",
              " '.update',\n",
              " '19',\n",
              " 'arguments',\n",
              " '(int',\n",
              " '.setname',\n",
              " 'arr',\n",
              " '.2',\n",
              " '34',\n",
              " '_fields',\n",
              " '_text',\n",
              " '42',\n",
              " 'where',\n",
              " '\"return',\n",
              " '_length',\n",
              " '.currenttoken',\n",
              " 'idx',\n",
              " '(p',\n",
              " '_and',\n",
              " '_add',\n",
              " '28',\n",
              " '26',\n",
              " 'dir',\n",
              " 'exp',\n",
              " '_ext',\n",
              " '35',\n",
              " 'state',\n",
              " 'does',\n",
              " '49',\n",
              " '(default',\n",
              " '27',\n",
              " '_code',\n",
              " '_order',\n",
              " '100',\n",
              " 'empty',\n",
              " '.decode',\n",
              " '51',\n",
              " 'run',\n",
              " '.to',\n",
              " '29',\n",
              " '56',\n",
              " '33',\n",
              " '_address',\n",
              " '.parametrize',\n",
              " '59',\n",
              " 'parseexception',\n",
              " '47',\n",
              " '36',\n",
              " '45',\n",
              " 'argument',\n",
              " '_content',\n",
              " 'project',\n",
              " 'fn',\n",
              " '_lib',\n",
              " '_script',\n",
              " 'same',\n",
              " ':2',\n",
              " '-8859',\n",
              " '55',\n",
              " '41',\n",
              " '48',\n",
              " 'columns',\n",
              " '\"invalid',\n",
              " '44',\n",
              " '39',\n",
              " '43',\n",
              " '82',\n",
              " '37',\n",
              " '.expr',\n",
              " 'attributeerror',\n",
              " 'right',\n",
              " '(sys',\n",
              " '57',\n",
              " '53',\n",
              " '_directory',\n",
              " '52',\n",
              " '46',\n",
              " '38',\n",
              " '.exprs',\n",
              " '54',\n",
              " '(node',\n",
              " '58',\n",
              " '_me',\n",
              " 'hash',\n",
              " '!r',\n",
              " '.environ',\n",
              " '61',\n",
              " '_vars',\n",
              " 'security',\n",
              " '.remove',\n",
              " 'items',\n",
              " '_on',\n",
              " '_bytes',\n",
              " 'archive',\n",
              " 'matching',\n",
              " '_or',\n",
              " '_response',\n",
              " 'min',\n",
              " '.errmsg',\n",
              " 'ax',\n",
              " 'keyerror',\n",
              " '.data',\n",
              " '_model',\n",
              " 'ignore',\n",
              " '_requirement',\n",
              " 'finally',\n",
              " '_output',\n",
              " '_unicode',\n",
              " 'rv',\n",
              " 'buf',\n",
              " 'each',\n",
              " '.dirname',\n",
              " 'freq',\n",
              " '=np',\n",
              " 'setup',\n",
              " 'django',\n",
              " '_user',\n",
              " '(res',\n",
              " '.value',\n",
              " '(base',\n",
              " 'last',\n",
              " '_distribution',\n",
              " '.values',\n",
              " '(5',\n",
              " '63',\n",
              " 'attribute',\n",
              " '_attr',\n",
              " 'namespace',\n",
              " '.req',\n",
              " 'then',\n",
              " 'instance',\n",
              " '_wheel',\n",
              " '_release',\n",
              " 'installed',\n",
              " '(item',\n",
              " 'keyword',\n",
              " 'random',\n",
              " '-tag',\n",
              " '_dist',\n",
              " 'callable',\n",
              " '(line',\n",
              " '-in',\n",
              " '_iter',\n",
              " 'iter',\n",
              " 'oth',\n",
              " 'doactions',\n",
              " '\"1',\n",
              " 'objects',\n",
              " '.default',\n",
              " 'env',\n",
              " '.base',\n",
              " 'attrs',\n",
              " 'ensure',\n",
              " '.key',\n",
              " 'information',\n",
              " '.strrepr',\n",
              " '(nums',\n",
              " '_spec',\n",
              " 'valid',\n",
              " '(k',\n",
              " 'sorted',\n",
              " '_like',\n",
              " '_obj',\n",
              " 'level',\n",
              " 'dt',\n",
              " '\"\\\\n',\n",
              " 'char',\n",
              " 'pos',\n",
              " 'color',\n",
              " 'environment',\n",
              " 'ssl',\n",
              " '-info',\n",
              " '_object',\n",
              " '.text',\n",
              " '[np',\n",
              " 'rev',\n",
              " 'src',\n",
              " '_paths',\n",
              " '_scheme',\n",
              " '_egg',\n",
              " '62',\n",
              " 'egg',\n",
              " 'dictionary',\n",
              " '[a',\n",
              " '.astype',\n",
              " 'convert',\n",
              " 'indent',\n",
              " '(input',\n",
              " '(type',\n",
              " \"'d\",\n",
              " 'regex',\n",
              " '.platform',\n",
              " 'movedmodule',\n",
              " '_py',\n",
              " '_number',\n",
              " '_keys',\n",
              " \"'r\",\n",
              " '_count',\n",
              " '_test',\n",
              " '.from',\n",
              " '(src',\n",
              " '.its',\n",
              " '.util',\n",
              " '_item',\n",
              " 'proxy',\n",
              " '_mode',\n",
              " '.type',\n",
              " '_ustr',\n",
              " '_msg',\n",
              " 'distributions',\n",
              " '_hash',\n",
              " '(list',\n",
              " '\"expected',\n",
              " 'suppress',\n",
              " '(4',\n",
              " 'conn',\n",
              " '_local',\n",
              " \"'build\",\n",
              " 'passed',\n",
              " 'types',\n",
              " 'notimplementederror',\n",
              " '@',\n",
              " '.warning',\n",
              " 'html',\n",
              " 'call',\n",
              " 'offset',\n",
              " 'six',\n",
              " 'params',\n",
              " 'characters',\n",
              " '[k',\n",
              " '_new',\n",
              " 'non',\n",
              " 'typing',\n",
              " 'fp',\n",
              " '.headers',\n",
              " '_links',\n",
              " '_encoding',\n",
              " 'into',\n",
              " 'o',\n",
              " '_i',\n",
              " 'connection',\n",
              " '(y',\n",
              " 'matches',\n",
              " '\"the',\n",
              " 'keys',\n",
              " '(func',\n",
              " 'num',\n",
              " '(typeerror',\n",
              " 'supported',\n",
              " 'urllib',\n",
              " '_chars',\n",
              " 'system',\n",
              " 'sequence',\n",
              " 'section',\n",
              " '_site',\n",
              " \"'w\",\n",
              " 'case',\n",
              " 'op',\n",
              " '_element',\n",
              " 'strings',\n",
              " '_only',\n",
              " 'was',\n",
              " 'json',\n",
              " '.run',\n",
              " 'row',\n",
              " '.check',\n",
              " '_request',\n",
              " '_p',\n",
              " 'packages',\n",
              " 'iterable',\n",
              " '?p',\n",
              " '_binary',\n",
              " 'position',\n",
              " 'byte',\n",
              " 'py',\n",
              " 'session',\n",
              " '_ver',\n",
              " '.has',\n",
              " '_lines',\n",
              " '_auth',\n",
              " '.link',\n",
              " 'allowed',\n",
              " 'instead',\n",
              " \"'1\",\n",
              " 'j',\n",
              " '_doc',\n",
              " 'global',\n",
              " '\"parseerror',\n",
              " '_label',\n",
              " 'netloc',\n",
              " 'fill',\n",
              " 'col',\n",
              " '_compare',\n",
              " 'than',\n",
              " '[4',\n",
              " 'cert',\n",
              " '\"d',\n",
              " 'w',\n",
              " 'collections',\n",
              " 'original',\n",
              " 'debug',\n",
              " '.dist',\n",
              " 'ip',\n",
              " '@staticmethod',\n",
              " 'setuptools',\n",
              " 'setattr',\n",
              " 'containing',\n",
              " 'column',\n",
              " '_mask',\n",
              " 'do',\n",
              " '.parseerror',\n",
              " 'comment',\n",
              " '.loc',\n",
              " '(arr',\n",
              " 'machinestate',\n",
              " 'resp',\n",
              " 'query',\n",
              " 'implementation',\n",
              " '_location',\n",
              " '_tags',\n",
              " 'filter',\n",
              " ',252',\n",
              " '_method',\n",
              " 'lib',\n",
              " 'pyparsing',\n",
              " '_extensions',\n",
              " 'frame',\n",
              " 'arch',\n",
              " '(var',\n",
              " 'orig',\n",
              " 'z',\n",
              " '(source',\n",
              " '_attributes',\n",
              " 'password',\n",
              " '(label',\n",
              " 'model',\n",
              " '(request',\n",
              " '(module',\n",
              " '_1',\n",
              " 'opt',\n",
              " \"'i\",\n",
              " \"'html\",\n",
              " 'remove',\n",
              " '+1',\n",
              " \"'f\",\n",
              " '.e',\n",
              " '_source',\n",
              " 'masked',\n",
              " 'single',\n",
              " 'dst',\n",
              " '(args',\n",
              " '_var',\n",
              " 'kind',\n",
              " '.put',\n",
              " 'prereleases',\n",
              " 'io',\n",
              " '_start',\n",
              " 'named',\n",
              " 'iterator',\n",
              " '_root',\n",
              " '_input',\n",
              " '_prereleases',\n",
              " 'flag',\n",
              " '_entry',\n",
              " '(element',\n",
              " '~',\n",
              " 'missing',\n",
              " 'load',\n",
              " 'available',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r2cY6t_IqjU"
      },
      "source": [
        "class TextGenerator(keras.callbacks.Callback):\n",
        "    \"\"\"A callback to generate text from a trained model.\n",
        "    1. Feed some starting prompt to the model\n",
        "    2. Predict probabilities for the next token\n",
        "    3. Sample the next token and add it to the next input\n",
        "\n",
        "    Arguments:\n",
        "        max_tokens: Integer, the number of tokens to be generated after prompt.\n",
        "        start_tokens: List of integers, the token indices for the starting prompt.\n",
        "        index_to_word: List of strings, obtained from the TextVectorization layer.\n",
        "        top_k: Integer, sample from the `top_k` token predictions.\n",
        "        print_every: Integer, print after this many epochs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, max_tokens, start_tokens, index_to_word, top_k=10, print_every=1\n",
        "    ):\n",
        "        self.max_tokens = max_tokens\n",
        "        self.start_tokens = start_tokens\n",
        "        self.index_to_word = index_to_word\n",
        "        self.print_every = print_every\n",
        "        self.k = top_k\n",
        "\n",
        "    def sample_from(self, logits):\n",
        "        logits, indices = tf.math.top_k(logits, k=self.k, sorted=True)\n",
        "        indices = np.asarray(indices).astype(\"int32\")\n",
        "        preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
        "        preds = np.asarray(preds).astype(\"float32\")\n",
        "        return np.random.choice(indices, p=preds)\n",
        "\n",
        "    def detokenize(self, number):\n",
        "        return self.index_to_word[number]\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        start_tokens = [_ for _ in self.start_tokens]\n",
        "        if (epoch + 1) % self.print_every != 0:\n",
        "            return\n",
        "        num_tokens_generated = 0\n",
        "        tokens_generated = []\n",
        "        while num_tokens_generated <= self.max_tokens:\n",
        "            pad_len = maxlen - len(start_tokens)\n",
        "            sample_index = len(start_tokens) - 1\n",
        "            if pad_len < 0:\n",
        "                x = start_tokens[:maxlen]\n",
        "                sample_index = maxlen - 1\n",
        "            elif pad_len > 0:\n",
        "                x = start_tokens + [0] * pad_len\n",
        "            else:\n",
        "                x = start_tokens\n",
        "            x = np.array([x])\n",
        "            y, _ = self.model.predict(x)\n",
        "            sample_token = self.sample_from(y[0][sample_index])\n",
        "            tokens_generated.append(sample_token)\n",
        "            start_tokens.append(sample_token)\n",
        "            num_tokens_generated = len(tokens_generated)\n",
        "        txt = \" \".join(\n",
        "            [self.detokenize(_) for _ in self.start_tokens + tokens_generated]\n",
        "        )\n",
        "        print(f\"generated text:\\n{txt}\\n\")\n",
        "\n",
        "\n",
        "# Tokenize starting prompt\n",
        "word_to_index = {}\n",
        "for index, word in enumerate(vocab):\n",
        "    word_to_index[word] = index\n",
        "\n",
        "start_prompt = \"for i in\"\n",
        "start_tokens = [word_to_index.get(_, 1) for _ in start_prompt.split()]\n",
        "num_tokens_generated = 40\n",
        "text_gen_callback = TextGenerator(num_tokens_generated, start_tokens, vocab)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmS1W_fjZaqs",
        "outputId": "d8577875-d283-4030-ac90-7bd34ca06556"
      },
      "source": [
        "for num, _ in enumerate(text_ds):\n",
        "    pass\n",
        "\n",
        "print(f'Number of elements: {num}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of elements: 2061254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0pS8oA4I5J3",
        "outputId": "a10d7165-731c-4354-95be-9766001cd197"
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "model.fit(text_ds,steps_per_epoch=num // batch_size, epochs=10, callbacks=[text_gen_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "68708/68708 [==============================] - 13582s 198ms/step - loss: 0.1870 - dense_2_loss: 0.1870\n",
            "generated text:\n",
            "for i in cases :                                       \n",
            "\n",
            "Epoch 2/10\n",
            "68708/68708 [==============================] - 13586s 198ms/step - loss: 0.1840 - dense_2_loss: 0.1840\n",
            "generated text:\n",
            "for i in range (len (self .files ) , -1 , -1 ) ,                              \n",
            "\n",
            "Epoch 3/10\n",
            "68708/68708 [==============================] - 14633s 213ms/step - loss: 0.1585 - dense_2_loss: 0.1585\n",
            "generated text:\n",
            "for i in range (self .shape :                                     \n",
            "\n",
            "Epoch 4/10\n",
            "  138/68708 [..............................] - ETA: 4:37:46 - loss: 0.2184 - dense_2_loss: 0.2184"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}